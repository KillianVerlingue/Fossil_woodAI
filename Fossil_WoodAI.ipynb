{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import des d√©pendences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# if using Apple MPS, fall back to CPU for unsupported ops\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import du mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
    "\n",
    "# checkpoint = \"/home/killian/sam2/checkpoints/sam2.1_hiera_large.pt\"\n",
    "# checkpoint = \"/home/killian/sam2/checkpoints/sam2.1_hiera_tiny.pt\"\n",
    "checkpoint = \"/home/killian/sam2/checkpoints/sam2.1_hiera_small.pt\"\n",
    "# model_cfg = \"configs/sam2.1/sam2.1_hiera_l.yaml\"\n",
    "# model_cfg = \"configs/sam2.1/sam2.1_hiera_t.yaml\"\n",
    "model_cfg = \"configs/sam2.1/sam2.1_hiera_s.yaml\"\n",
    "# predictor = SAM2ImagePredictor(build_sam2(model_cfg, checkpoint))\n",
    "\n",
    "sam2 = build_sam2(model_cfg, checkpoint, device=\"cuda\", apply_postprocessing=False)\n",
    "\n",
    "mask_generator = SAM2AutomaticMaskGenerator(sam2)\n",
    "# with torch.inference_mode(), torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "    # predictor.set_image(\"/home/killian/sam2\")\n",
    "    # masks, _, _ = predictor.predict(\"0\")\n",
    "    # üîπ Chemins vers le mod√®le et la configuration\n",
    "#checkpoint = \"./checkpoints/sam2_hiera_large.pt\"\n",
    "#model_cfg = \"sam2_hiera_l.yaml\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on d√©finit le DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import tifffile\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, input_raster, tile_size=640, stride=10, transforms=None):\n",
    "        self.raster = tifffile.imread(input_raster)\n",
    "        self.tile_size = tile_size\n",
    "        self.stride = stride\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        # R√©cup√©rer la hauteur et la largeur de l'image\n",
    "        self.H, self.W, self.C = self.raster.shape\n",
    "        \n",
    "        # Calcul du nombre de patchs de droite √† gauche en balayant horizontalement\n",
    "        self.num_patches = (self.W - tile_size) // stride + 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_patches\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # D√©finir les limites de d√©coupage de droite √† gauche\n",
    "        start_x = self.W - (idx * self.stride + self.tile_size)\n",
    "        end_x = start_x + self.tile_size\n",
    "        \n",
    "        if start_x < 0:\n",
    "            start_x, end_x = 0, self.tile_size  # Assurer une extraction valide\n",
    "        \n",
    "        # Extraire une bande horizontale de droite √† gauche\n",
    "        data = self.raster[:, start_x:end_x, :]\n",
    "        \n",
    "        # R√©organiser les axes pour correspondre √† (H, W, C)\n",
    "        data = np.transpose(data, (0, 1, 2))\n",
    "        \n",
    "        # Appliquer une √©ventuelle transformation\n",
    "        if self.transforms:\n",
    "            data = self.transforms(data)\n",
    "        \n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloader et dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# dataset = CustomDataset('/home/killian/data2025/15485/X200_15485_PB1.tif', tile_size=640, stride=10)\n",
    "dataset = CustomDataset('/home/killian/data2025/TGV4/X200_TGV4A_B_P.tif', tile_size=640, stride=10)\n",
    "dataloader = DataLoader(dataset,batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparametres mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparametres\n",
    "model = SAM2AutomaticMaskGenerator(\n",
    "    model=sam2,\n",
    "    points_per_side=20,  # Plus de points pour capturer les details\n",
    "    points_per_batch=30,  # Augmenter pour calculer le nbre de points pris en meme temps (/!\\ GPU)\n",
    "    pred_iou_thresh=0.7,  # Reduire pour accepter plus de mask\n",
    "    stability_score_thresh=0.70,  # Rzduire pour ne pas exclure trop de mask\n",
    "    stability_score_offset=0.8,\n",
    "    crop_n_layers=2,  # Ammeliore la segmentation des petites structures\n",
    "    box_nms_thresh=0.70,  # Eviter la suppression excessive de petite structure\n",
    "    crop_n_points_downscale_factor=1.5,  # Adapter aux images a haute resolution\n",
    "    min_mask_region_area=15.0,  # Conserver plus de petits objets\n",
    "    use_m2m=True,  # Mode avanc√© \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 640, 12545)Avancement : 0.00%\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import cv2\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Dossier de sortie\n",
    "output_dir = \"/home/killian/sam2/inferences\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Fichiers CSV pour sauvegarder les masks\n",
    "csv_masks_file = os.path.join(output_dir, \"mask_measurements.csv\")\n",
    "\n",
    "with open(csv_masks_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Image_ID\", \"Mask_ID\", \"Centroid_X\", \"Centroid_Y\", \"Area\", \"Equivalent_Diameter\"])\n",
    "\n",
    "size_threshold = 560  # Seuil pour filtrer les objets trop grands\n",
    "# (0.5060 px/¬µm) donc <280¬µm pour\n",
    "\n",
    "# Boucle d'inf√©rence\n",
    "for i, image in enumerate(dataloader):\n",
    "    print(f\"Image {i+1}/{len(dataloader)} - Avancement : {i/len(dataloader):.2%}\", end='\\r')\n",
    "    \n",
    "    image_np = image.squeeze(0).cpu().numpy()\n",
    "    image_np = image_np.swapaxes(0, 2)\n",
    "    print(image_np.shape)\n",
    "    pred = model.generate(image_np)\n",
    "    \n",
    "    res_tensor = torch.stack([torch.tensor(m['segmentation'], dtype=torch.bool) for m in pred])\n",
    "    filtered_tensor = res_tensor[res_tensor.sum(dim=(1, 2)) <= size_threshold]\n",
    "    res_merge = filtered_tensor.any(dim=0).to(device)\n",
    "    \n",
    "    # Trier les masques de droite √† gauche selon la coordonn√©e X de leur centro√Øde\n",
    "    masks_info = []\n",
    "    for mask_id, mask_pred in enumerate(filtered_tensor):\n",
    "        mask_np = mask_pred.cpu().numpy().astype(np.uint8)\n",
    "        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_np, connectivity=8)\n",
    "        \n",
    "        for j in range(1, num_labels):  # On ignore le label 0 (arri√®re-plan)\n",
    "            x, y = centroids[j]\n",
    "            area = stats[j, cv2.CC_STAT_AREA]\n",
    "            equivalent_diameter = np.sqrt(4 * area / np.pi)\n",
    "            masks_info.append((x, y, area, equivalent_diameter, mask_id))\n",
    "            \n",
    "    # Trier les masques en fonction de X (croissant)\n",
    "    masks_info.sort(reverse=True, key=lambda m: m[0])\n",
    "    \n",
    "    # Sauvegarde des masques tri√©s\n",
    "    with open(csv_masks_file, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for x, y, area, equivalent_diameter, mask_id in masks_info:\n",
    "            writer.writerow([f\"Image_{i}\", mask_id, x, y, area, equivalent_diameter])\n",
    "    \n",
    "    # Sauvegarde de l'image de pr√©diction et de l'image originale\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image_np)\n",
    "    plt.title(\"Image Originale\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(res_merge.cpu().numpy(), cmap='gray')\n",
    "    plt.title(\"Masques Pr√©dits\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.savefig(os.path.join(output_dir, f\"Image_{i}.png\"))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 19/19 - Avancement : 94.74%\r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import cv2\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Dossier de sortie\n",
    "output_dir = \"/home/killian/sam2/inferences\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Fichiers CSV pour sauvegarder les masks\n",
    "csv_masks_file = os.path.join(output_dir, \"mask_measurements.csv\")\n",
    "\n",
    "with open(csv_masks_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Image_ID\", \"Mask_ID\", \"Centroid_X\", \"Centroid_Y\", \"Area\", \"Equivalent_Diameter\", \"Length\"])\n",
    "\n",
    "size_threshold = 560  # Seuil pour filtrer les objets trop grands\n",
    "\n",
    "# Boucle d'inf√©rence\n",
    "for i, image in enumerate(dataloader):\n",
    "    print(f\"Image {i+1}/{len(dataloader)} - Avancement : {i/len(dataloader):.2%}\", end='\\r')\n",
    "    \n",
    "    image_np = image.squeeze(0).cpu().numpy()\n",
    "    image_np = image_np = image_np.swapaxes(1, 2)\n",
    "    pred = model.generate(image_np)\n",
    "    \n",
    "    res_tensor = torch.stack([torch.tensor(m['segmentation'], dtype=torch.bool) for m in pred])\n",
    "    filtered_tensor = res_tensor[res_tensor.sum(dim=(1, 2)) <= size_threshold]\n",
    "    res_merge = filtered_tensor.any(dim=0).to(device)\n",
    "    \n",
    "    # Trier les masques de droite √† gauche\n",
    "    masks_info = []\n",
    "    for mask_id, mask_pred in enumerate(filtered_tensor):\n",
    "        mask_np = mask_pred.cpu().numpy().astype(np.uint8)\n",
    "        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_np, connectivity=8)\n",
    "        \n",
    "        for j in range(1, num_labels):  # On ignore le label 0 (arri√®re-plan)\n",
    "            x, y = centroids[j]\n",
    "            area = stats[j, cv2.CC_STAT_AREA]\n",
    "            equivalent_diameter = np.sqrt(4 * area / np.pi)\n",
    "            masks_info.append((x, y, area, equivalent_diameter, mask_id))\n",
    "    \n",
    "    # Trier de droite √† gauche (X d√©croissant)\n",
    "    masks_info.sort(reverse=True, key=lambda m: m[0])\n",
    "    \n",
    "    # S√©lectionner une seule file cellulaire √† l'horizontale\n",
    "    selected_masks = []\n",
    "    tolerance = 20  # Tol√©rance pour regrouper les masques horizontalement\n",
    "    \n",
    "    for mask in masks_info:\n",
    "        x, y, _, _, mask_id = mask\n",
    "        if not selected_masks or abs(selected_masks[-1][0] - x) < tolerance:\n",
    "            selected_masks.append(mask)\n",
    "    \n",
    "    # Calculer la longueur totale de la file cellulaire\n",
    "    if selected_masks:\n",
    "        min_x = min(m[0] for m in selected_masks)\n",
    "        max_x = max(m[0] for m in selected_masks)\n",
    "        length = max_x - min_x\n",
    "    else:\n",
    "        length = 0\n",
    "    \n",
    "    # Sauvegarde des masques s√©lectionn√©s\n",
    "    with open(csv_masks_file, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for x, y, area, equivalent_diameter, mask_id in selected_masks:\n",
    "            writer.writerow([f\"Image_{i}\", mask_id, x, y, area, equivalent_diameter, length])\n",
    "    \n",
    "    # Sauvegarde des images\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image_np)\n",
    "    plt.title(\"Image Originale\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    final_mask = np.zeros_like(res_merge.cpu().numpy())\n",
    "    for x, _, _, _, mask_id in selected_masks:\n",
    "        final_mask += filtered_tensor[mask_id].cpu().numpy()\n",
    "    \n",
    "    plt.imshow(final_mask, cmap='gray')\n",
    "    plt.title(\"File Cellulaire S√©lectionn√©e (Horizontale)\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.savefig(os.path.join(output_dir, f\"Image_{i}.png\"))\n",
    "    plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
