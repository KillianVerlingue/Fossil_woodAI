
# import des dependences
import os
import csv
import torch
import torchmetrics
import numpy as np
import matplotlib.pyplot as plt
import cv2
# if using Apple MPS, fall back to CPU for unsupported ops
os.environ["PYTORCH_ENABLE_MPS_FALLBACK"] = "1"
from PIL import Image


# Import de sam2
from sam2.build_sam import build_sam2
from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator

# checkpoint = "/home/killian/sam2/checkpoints/sam2.1_hiera_large.pt"
checkpoint = "/home/killian/sam2/checkpoints/sam2.1_hiera_tiny.pt"
# model_cfg = "configs/sam2.1/sam2.1_hiera_l.yaml"
model_cfg = "configs/sam2.1/sam2.1_hiera_t.yaml"
# predictor = SAM2ImagePredictor(build_sam2(model_cfg, checkpoint))

sam2 = build_sam2(model_cfg, checkpoint, device="cuda", apply_postprocessing=False)

mask_generator = SAM2AutomaticMaskGenerator(sam2)
# with torch.inference_mode(), torch.autocast("cuda", dtype=torch.bfloat16):
    # predictor.set_image("/home/killian/sam2")
    # masks, _, _ = predictor.predict("0")
    # üîπ Chemins vers le mod√®le et la configuration
#checkpoint = "./checkpoints/sam2_hiera_large.pt"
#model_cfg = "sam2_hiera_l.yaml"

#Hyperparametres
model = SAM2AutomaticMaskGenerator(
    model=sam2,
    points_per_side=20,  # Plus de points pour capturer les details
    points_per_batch=30,  # Augmenter pour calculer le nbre de points pris en meme temps (/!\ GPU)
    pred_iou_thresh=0.7,  # Reduire pour accepter plus de mask
    stability_score_thresh=0.80,  # Rzduire pour ne pas exclure trop de mask
    stability_score_offset=0.8,
    crop_n_layers=2,  # Ammeliore la segmentation des petites structures
    box_nms_thresh=0.80,  # Eviter la suppression excessive de petite structure
    crop_n_points_downscale_factor=2,  # Adapter aux images a haute resolution
    min_mask_region_area=15.0,  # Conserver plus de petits objets
    use_m2m=True,  # Mode avanc√© 
)

# D√©finition du device
device = "cuda"

# D√©finition des m√©triques
miou = torchmetrics.JaccardIndex(task='binary', num_classes=1).to(device)
precision = torchmetrics.Precision(task='binary').to(device)
recall = torchmetrics.Recall(task='binary').to(device)
f1_score = torchmetrics.F1Score(task='binary').to(device)

# Dossier de sortie
output_dir = "/home/killian/sam2/predictions"
os.makedirs(output_dir, exist_ok=True)

# Fichier CSV pour les m√©triques globales
csv_file = os.path.join(output_dir, "sam2_results.csv")
with open(csv_file, mode='w', newline='') as file:
    writer = csv.writer(file)
    writer.writerow(["Image_ID", "IoU", "Precision", "Recall", "F1_Score", "Num_Masks", "Num_Masks_Label"])

# Fichier CSV pour les mesures des masques
csv_masks_file = os.path.join(output_dir, "mask_measurements.csv")
with open(csv_masks_file, mode='w', newline='') as file:
    writer = csv.writer(file)
    writer.writerow(["Image_ID", "Mask_ID", "Centroid_X", "Centroid_Y", "Area", "Equivalent_Diameter"])

size_threshold = 10000  # Seuil pour filtrer les objets trop grands

# Variables pour les moyennes
total_miou = total_precision = total_recall = total_f1 = total_images = 0

for i, (batch, mask) in enumerate(dataloader):
    print(f"Image {i+1}/{len(dataloader)} - Avancement : {i/len(dataloader):.2%}", end='\r')
    batch = batch.to(device)

    for idx, (image, label) in enumerate(zip(batch, mask)):
        image_np = image.cpu().numpy()
        pred = model.generate(image_np)
        
        res_tensor = torch.stack([torch.tensor(m['segmentation'], dtype=torch.bool) for m in pred])
        filtered_tensor = res_tensor[res_tensor.sum(dim=(1, 2)) <= size_threshold]
        res_merge = filtered_tensor.any(dim=0).to(device)
        
        label_np = np.array(label)
        trach = torch.as_tensor(label_np[:, :, 2], dtype=torch.bool, device=device) if label_np.ndim == 3 and label_np.shape[-1] >= 3 else torch.as_tensor(label_np, dtype=torch.bool, device=device)
        
        num_masks_label = (label_np > 0).sum()
        
        # Calcul des m√©triques
        img_miou = miou(res_merge, trach).item()
        img_precision = precision(res_merge, trach).item()
        img_recall = recall(res_merge, trach).item()
        img_f1 = f1_score(res_merge, trach).item()
        
        total_miou += img_miou
        total_precision += img_precision
        total_recall += img_recall
        total_f1 += img_f1
        total_images += 1
        
        # Sauvegarde des r√©sultats dans le CSV
        with open(csv_file, mode='a', newline='') as file:
            writer = csv.writer(file)
            writer.writerow([f"Image_{i}_{idx}", img_miou, img_precision, img_recall, img_f1, filtered_tensor.shape[0], num_masks_label])
        
        # Mesure des aires et centro√Ødes des masques
        for mask_id, mask_pred in enumerate(filtered_tensor):
            mask_np = mask_pred.cpu().numpy().astype(np.uint8)
            num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_np, connectivity=8)
            
            with open(csv_masks_file, mode='a', newline='') as file:
                writer = csv.writer(file)
                for j in range(1, num_labels):
                    x, y = centroids[j]
                    area = stats[j, cv2.CC_STAT_AREA]
                    equivalent_diameter = np.sqrt(4 * area / np.pi)
                    writer.writerow([f"Image_{i}_{idx}", mask_id, x, y, area, equivalent_diameter])
        
        # Sauvegarde des images
        plt.figure(figsize=(12, 5))
        plt.subplot(1, 2, 1)
        plt.title("Pr√©diction")
        plt.imshow(res_merge.cpu().numpy(), cmap='gray')
        plt.axis('off')
        
        plt.subplot(1, 2, 2)
        plt.title("Label")
        plt.imshow(trach.cpu().numpy(), cmap='gray')
        plt.axis('off')
        
        plt.savefig(os.path.join(output_dir, f"Image_{i}_{idx}.png"))
        plt.close()

if total_images > 0:
    mean_miou = total_miou / total_images
    mean_precision = total_precision / total_images
    mean_recall = total_recall / total_images
    mean_f1 = total_f1 / total_images
    
    print(f"mIoU moyen: {mean_miou:.4f}")
    print(f"Pr√©cision moyenne: {mean_precision:.4f}")
    print(f"Rappel moyen: {mean_recall:.4f}")
    print(f"F1-Score moyen: {mean_f1:.4f}")

